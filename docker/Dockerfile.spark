# /docker/Dockerfile.spark
FROM bitnami/spark:3.3.1

USER root

# Instala python3, python3-pip, netcat-traditional y curl
RUN apt-get update && apt-get install -y --no-install-recommends python3 python3-pip netcat-traditional curl

COPY docker/requirements_spark.txt /tmp/requirements_spark.txt
RUN pip3 install --no-cache-dir --upgrade pip && \
    pip3 install --no-cache-dir -r /tmp/requirements_spark.txt

# Copia SOLO el código necesario de Spark.
COPY src/spark_jobs /opt/bitnami/spark/src/spark_jobs

WORKDIR /opt/bitnami/spark

EXPOSE 4040

# Usa el spark-submit directamente.  El entrypoint de Bitnami se encargará de Kafka.
CMD ["spark-submit", "--master", "local[*]", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1", "src/spark_jobs/process_tickets.py"]